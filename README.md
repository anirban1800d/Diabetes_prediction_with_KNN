# Diabetes_prediction_with_KNN
This project implements an optimized machine learning pipeline for predicting diabetes by combining dimensionality reduction, wrapper-based feature selection, and distance-based classification. Instead of relying on a plain model, the focus is on improving generalization, reducing noise, and selecting only the most informative features.

# ğŸ”¥ Why this project?

Most ML notebooks stop at â€œtrain â†’ accuracy â†’ done.â€
This project goes deeper.

It builds a noise-free, optimized, Kaggle-ready classification engine that carefully selects only the most meaningful information before making medical predictions.

Less noise. More signal. Smarter predictions.

# ğŸ§  Whatâ€™s happening under the hood?

Raw Medical Data
      â†“
Feature Scaling
      â†“
Principal Component Analysis (PCA)
      â†“
Sequential Feature Selection (mlxtend)
      â†“
Distance-Weighted KNN Classifier
      â†“
Probability-Based Predictions

# âœ‚ï¸ Smart Feature Pruning

â€¢ 24 original features
â€¢ Reduced to 22 PCA components
â€¢ Further refined to only 9 elite components using Sequential Feature Selection

(0, 3, 4, 6, 10, 12, 18, 19, 21)

# Fewer features â†’ Faster model â†’ Better generalization.
